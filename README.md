# DetecÃ§Ã£o de Anomalias (Projeto AMCD)

Projeto da disciplina de **Aprendizado de MÃ¡quina e CiÃªncia de Dados (AMCD)**.

**Objetivo:** Implementar e comparar trÃªs abordagens distintas (**Deep Learning**, **Densidade** e **ProbabilÃ­stica**) para a detecÃ§Ã£o de anomalias/fraudes em um conjunto de dados desbalanceado.

---

## Modelos Implementados

1. **Autoencoder** â€” Abordagem de ReconstruÃ§Ã£o
2. **DBSCAN** â€” Abordagem de Densidade
3. **Gaussian Mixture Models (GMM)** â€” Abordagem ProbabilÃ­stica

---

## Dataset

Utilizaremos o dataset **Credit Card Fraud Detection**, disponÃ­vel no Kaggle.

### CaracterÃ­sticas

- **ConteÃºdo:** TransaÃ§Ãµes de cartÃµes de crÃ©dito de clientes europeus em setembro de 2013.
- **Volume:** 284.807 transaÃ§Ãµes.
- **Desbalanceamento:** Apenas 492 fraudes (0,172%). Dataset altamente desbalanceado, com classe positiva rara.
- **Privacidade:** As features `V1`, `V2`, ..., `V28` sÃ£o o resultado de uma transformaÃ§Ã£o **PCA (Principal Component Analysis)**, aplicada para proteger a identidade dos usuÃ¡rios.
- **Features Originais:** Apenas `Time` (segundos desde a primeira transaÃ§Ã£o) e `Amount` (valor da transaÃ§Ã£o) nÃ£o foram transformadas.

### Justificativa da Escolha

Optamos por este dataset para concentrar o esforÃ§o do projeto na **comparaÃ§Ã£o algorÃ­tmica** e na **anÃ¡lise de sensibilidade dos modelos**. Como as principais features jÃ¡ passaram por PCA, elas apresentam propriedades estatÃ­sticas relevantes â€” como descorrelaÃ§Ã£o â€” que favorecem a convergÃªncia de modelos como **GMM** e **Autoencoders**. Isso permite uma anÃ¡lise mais profunda das nuances de cada abordagem, reduzindo o impacto de ruÃ­dos tÃ­picos de dados brutos nÃ£o estruturados.

---

## DivisÃ£o de PapÃ©is e Responsabilidades

O projeto adota uma estrutura de trabalho **modular e paralela**, permitindo que as atividades avancem simultaneamente com **baixo acoplamento** entre as partes.  
A **Engenharia de Dados** fornece a base comum para a **Modelagem**, reduzindo gargalos de integraÃ§Ã£o.

### PapÃ©is do Projeto

| Papel | Integrante | Foco | Responsabilidades |
|------|------------|------|-------------------|
| **Eng. de Dados & AvaliaÃ§Ã£o** | *Integrante 1* | Infraestrutura e MÃ©tricas | â€¢ Limpeza, normalizaÃ§Ã£o e split dos dados<br>â€¢ GeraÃ§Ã£o dos arquivos em `data/processed/`<br>â€¢ ImplementaÃ§Ã£o do `evaluation.py`<br>â€¢ CÃ¡lculo de mÃ©tricas (AUC-ROC, F1, Recall)<br>â€¢ GeraÃ§Ã£o de grÃ¡ficos comparativos |
| **Esp. em Deep Learning** | *Integrante 2* | Autoencoder (ReconstruÃ§Ã£o) | â€¢ ImplementaÃ§Ã£o do `autoencoder.py` (Keras/PyTorch)<br>â€¢ Ajuste do gargalo (*bottleneck*) e *learning rate*<br>â€¢ GeraÃ§Ã£o do `anomaly_score` via **erro de reconstruÃ§Ã£o** |
| **Esp. em Densidade** | *Integrante 3* | DBSCAN (Geometria / RuÃ­do) | â€¢ AplicaÃ§Ã£o de PCA para otimizar o modelo<br>â€¢ ImplementaÃ§Ã£o do `dbscan.py`<br>â€¢ Ajuste de `epsilon` e `min_samples`<br>â€¢ Uso da classe `-1` (ruÃ­do) como anomalia |
| **Esp. ProbabilÃ­stico** | *Integrante 4* | GMM (DistribuiÃ§Ã£o) | â€¢ ImplementaÃ§Ã£o do `gmm.py`<br>â€¢ Ajuste do nÃºmero de componentes e tipo de covariÃ¢ncia<br>â€¢ CÃ¡lculo do `anomaly_score` via **probabilidade invertida** \\(1 âˆ’ P(x)\\) |

---

## Contrato de Interface de Dados

O **Contrato de Interface de Dados** define formalmente os **formatos de entrada e saÃ­da** utilizados no projeto.  
Seu objetivo Ã© permitir **desenvolvimento paralelo**, garantindo que o **Engenheiro de Dados & AvaliaÃ§Ã£o (Integrante 1)** consiga integrar e comparar os resultados dos trÃªs modelos **sem incompatibilidades**.

### Entrada dos Modelos  
**Responsabilidade exclusiva: Integrante 1 (Engenharia de Dados & AvaliaÃ§Ã£o)**

O Integrante 1 Ã© o **Ãºnico responsÃ¡vel** por gerar, validar e versionar os arquivos abaixo na pasta `data/processed/`.  
Todos os modelos **devem consumir exatamente esses arquivos**, sem exceÃ§Ãµes.

| Arquivo | ConteÃºdo Garantido | ResponsÃ¡vel | Justificativa |
|-------|------------------|------------|---------------|
| **`X_train_processed.csv`** | Features numÃ©ricas **normalizadas**, sem ID e sem `target` | Integrante 1 | Base de treino limpa para aprendizado **nÃ£o supervisionado**, focada na estrutura dos dados normais |
| **`X_test_processed.csv`** | Features de teste, sem ID e sem `target` | Integrante 1 | Garante avaliaÃ§Ã£o justa, com os trÃªs modelos testados no **mesmo conjunto de dados** |
| **`y_test.csv`** | Coluna Ãºnica binÃ¡ria (`0 = Normal`, `1 = Anomalia`) | Integrante 1 | Gabarito oficial (`y_true`) para cÃ¡lculo de mÃ©tricas |
| **`ids_test.csv`** | Coluna Ãºnica com IDs das transaÃ§Ãµes | Integrante 1 | Permite o alinhamento entre prediÃ§Ãµes e gabarito, assegurando a integridade dos resultados |

---

### SaÃ­da dos Modelos  
**Responsabilidade: Integrantes 2, 3 e 4 (Modelagem)**

Cada especialista em modelagem deve salvar suas prediÃ§Ãµes na pasta `outputs/`, **obedecendo rigorosamente** ao formato definido neste contrato.

- **Nome do arquivo:** [nome_modelo]_predictions.csv
Exemplo: `autoencoder_predictions.csv`

### Estrutura ObrigatÃ³ria do CSV

| Coluna | Tipo | Finalidade |
|------|------|------------|
| **`id`** | int / str | **Chave de cruzamento** usada para alinhar a prediÃ§Ã£o ao `y_test.csv` |
| **`anomaly_score`** | float | **Score contÃ­nuo** utilizado para cÃ¡lculo da **Curva ROC** e do **AUC-ROC** (capacidade mÃ¡xima do modelo) |
| **`is_anomaly`** | int (0 ou 1) | ClassificaÃ§Ã£o binÃ¡ria apÃ³s aplicaÃ§Ã£o do *threshold*, usada para mÃ©tricas como **F1-score** e **Recall** |

### ğŸ“Œ Exemplo de CSV de SaÃ­da (Contrato de Interface)

```csv
id,anomaly_score,is_anomaly
1024,0.954,1
1025,0.021,0
1026,0.110,0
```

---

## Estrutura do RepositÃ³rio

O mÃ©todo de organizaÃ§Ã£o visa separar dados brutos, cÃ³digo de exploraÃ§Ã£o (notebooks) e cÃ³digo de produÃ§Ã£o (`src`).

```text
projeto-anomalia/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                  # Dados originais imutÃ¡veis (NÃƒO commitar arquivos grandes)
â”‚   â”œâ”€â”€ processed/            # Dados limpos e normalizados (gerados pelo script de limpeza)
â”‚   â””â”€â”€ mocks/                # Dados falsos para testes de integraÃ§Ã£o
â”œâ”€â”€ notebooks/                # Ãrea de experimentaÃ§Ã£o e rascunho
â”‚   â”œâ”€â”€ 01_eda_analise.ipynb
â”‚   â”œâ”€â”€ 02_proto_autoencoder.ipynb
â”‚   â”œâ”€â”€ 02_proto_dbscan.ipynb
â”‚   â””â”€â”€ 02_proto_gmm.ipynb
â”œâ”€â”€ src/                      # CÃ³digo final modularizado
â”‚   â”œâ”€â”€ preprocessing.py      # FunÃ§Ãµes de limpeza e split
â”‚   â”œâ”€â”€ evaluation.py         # FunÃ§Ãµes para curvas ROC e mÃ©tricas
â”‚   â””â”€â”€ models/               # Scripts finais dos modelos
â”‚       â”œâ”€â”€ autoencoder.py
â”‚       â”œâ”€â”€ dbscan.py
â”‚       â””â”€â”€ gmm.py
â”œâ”€â”€ outputs/                  # PrediÃ§Ãµes salvas pelos modelos (CSV)
â”œâ”€â”€ requirements.txt          # DependÃªncias do projeto
â””â”€â”€ README.md                 # Este arquivo
```

---

## Branches

* **main**: ProduÃ§Ã£o. atualizaÃ§Ã£o exclusivamente via *Pull Request* (PR).
* **preprocessing**: Limpeza, EDA e split dos dados.
* **model-autoencoder**: Desenvolvimento da Rede Neural.
* **model-dbscan**: Desenvolvimento do DBSCAN e PCA.
* **model-gmm**: Desenvolvimento do GMM e anÃ¡lise de distribuiÃ§Ã£o.

### Fluxo de Trabalho

1. Crie sua branch a partir da `main`.
2. Desenvolva e teste no seu notebook.
3. Exporte o cÃ³digo limpo para a pasta `src/`.
4. Abra um *Pull Request* para a `main` ao finalizar.

---

## Como Executar (Ambiente)

Para garantir compatibilidade, todos devem usar as mesmas versÃµes das bibliotecas.

### Clone o repositÃ³rio

```bash
git clone https://github.com/maqvn/Deteccao-de-Anomalias.git
```

### Crie um ambiente virtual (opcional, mas recomendado)

```bash
python -m venv venv
source venv/bin/activate  # Linux / Mac
venv\Scripts\activate     # Windows
```

### Instale as dependÃªncias

```bash
pip install -r requirements.txt
```

---

## Desenvolvimento com Mocks

Enquanto os dados reais nÃ£o estiverem prontos (limpeza em andamento), utilize os arquivos da pasta `data/mocks/`.

* Possuem a **mesma estrutura de colunas e tipos de dados** dos arquivos reais.
* Seu cÃ³digo deve funcionar alterando apenas o caminho de leitura de `data/processed/` para `data/mocks/`.
