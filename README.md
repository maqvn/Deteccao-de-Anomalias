# Detec√ß√£o de Anomalias (Projeto AMCD)

Projeto desenvolvido para a disciplina de **Aprendizado de M√°quina e Ci√™ncia de Dados (AMCD)**, com foco na compara√ß√£o de diferentes abordagens para **detec√ß√£o de anomalias/fraudes** em dados altamnte desbalanceados.

---

## Objetivo do Projeto

Implementar, avaliar e comparar tr√™s paradigmas distintos de detec√ß√£o de anomalias:

* **Deep Learning** (Reconstru√ß√£o)
* **Modelos Baseados em Densidade**
* **Modelos Probabil√≠sticos**

A compara√ß√£o √© realizada sob um mesmo conjunto de dados, protocolo experimental e m√©tricas, garantindo uma an√°lise justa e reprodut√≠vel.

---

## Modelos Implementados

1. **Autoencoder** ‚Äî Abordagem de Reconstru√ß√£o
2. **DBSCAN** ‚Äî Abordagem de Densidade
3. **Gaussian Mixture Models (GMM)** ‚Äî Abordagem Probabil√≠stica

---

## Dataset Utilizado

Ser√° utilizado o dataset **Credit Card Fraud Detection**, disponibilizado publicamente no Kaggle.

### Caracter√≠sticas Principais

* **Conte√∫do:** Transa√ß√µes de cart√µes de cr√©dito de clientes europeus (setembro de 2013).
* **Volume:** 284.807 transa√ß√µes.
* **Desbalanceamento:** Apenas 492 fraudes (0,172%), caracterizando um cen√°rio altamente desbalanceado.
* **Privacidade:** As features `V1`, `V2`, ..., `V28` resultam de uma transforma√ß√£o por **PCA (Principal Component Analysis)**, aplicada para anonimiza√ß√£o.
* **Features N√£o Transformadas:**

  * `Time`: segundos desde a primeira transa√ß√£o
  * `Amount`: valor da transa√ß√£o

### Justificativa da Escolha

A escolha deste dataset permite concentrar o esfor√ßo do projeto na **an√°lise algor√≠tmica** e na **sensibilidade dos modelos**, minimizando problemas oriundos de dados brutos n√£o estruturados.

Como as principais features j√° passaram por PCA, elas apresentam propriedades estat√≠sticas desej√°veis ‚Äî como descorrela√ß√£o ‚Äî que favorecem a converg√™ncia e estabilidade de modelos como **GMM** e **Autoencoders**, possibilitando uma compara√ß√£o mais precisa entre abordagens.

### Instala√ß√£o do Dataset (Dados Reais)

Devido ao tamanho (~150MB) e √†s boas pr√°ticas de versionamento, o dataset original **n√£o est√° inclu√≠do no reposit√≥rio**.

1.  **Download:** Acesse a p√°gina oficial no Kaggle: [Credit Card Fraud Detection](https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud).
2.  **Arquivo:** Baixe e extraia o arquivo `creditcard.csv`.
3.  **Localiza√ß√£o:** Salve o arquivo exatamente no seguinte caminho:
    ```text
    data/raw/creditcard.csv
    ```
    > **Nota:** O arquivo `.gitignore` deste projeto j√° est√° configurado para ignorar qualquer CSV na pasta `data/raw/`, garantindo que dados sens√≠veis ou pesados n√£o sejam enviados ao GitHub.

---

## Organiza√ß√£o do Trabalho

O projeto adota uma estrutura **modular e paralela**, permitindo que diferentes partes avancem simultaneamente com **baixo acoplamento**. Um contrato claro de dados e responsabilidades reduz conflitos de integra√ß√£o.

### Divis√£o de Pap√©is e Responsabilidades

| Papel                         | Integrante     | Foco                      | Responsabilidades                                                                                                                                                                                                  |
| ----------------------------- | -------------- | ------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |
| **Eng. de Dados & Avalia√ß√£o** | *Integrante 1* | Infraestrutura e M√©tricas | ‚Ä¢ Limpeza, normaliza√ß√£o e split dos dados<br>‚Ä¢ Gera√ß√£o de arquivos em `data/processed/`<br>‚Ä¢ Implementa√ß√£o do `evaluation.py`<br>‚Ä¢ C√°lculo de m√©tricas (AUC-ROC, F1, Recall)<br>‚Ä¢ Gera√ß√£o de gr√°ficos comparativos |
| **Esp. em Deep Learning**     | *Integrante 2* | Autoencoder               | ‚Ä¢ Implementa√ß√£o do `autoencoder.py` (Keras/PyTorch)<br>‚Ä¢ Ajuste do gargalo (*bottleneck*) e *learning rate*<br>‚Ä¢ Gera√ß√£o do `anomaly_score` via erro de reconstru√ß√£o                                               |
| **Esp. em Densidade**         | *Integrante 3* | DBSCAN                    | ‚Ä¢ Aplica√ß√£o de PCA para otimiza√ß√£o<br>‚Ä¢ Implementa√ß√£o do `dbscan.py`<br>‚Ä¢ Ajuste de `epsilon` e `min_samples`<br>‚Ä¢ Uso da classe `-1` como anomalia                                                                |
| **Esp. Probabil√≠stico**       | *Integrante 4* | GMM                       | ‚Ä¢ Implementa√ß√£o do `gmm.py`<br>‚Ä¢ Ajuste do n√∫mero de componentes e covari√¢ncia<br>‚Ä¢ C√°lculo do `anomaly_score` via probabilidade invertida (1 ‚àí P(x))                                                              |

---

## Contrato de Interface de Dados

### Entrada dos Modelos (`data/processed/`)

* `X_train_processed.csv` ‚Äî Features normalizadas (sem target e sem ID)
* `y_train.csv` ‚Äî Gabarito (0 = Normal, 1 = Anomalia)
* `X_test_processed.csv` ‚Äî Mesmo formato do treino
* `y_test.csv` ‚Äî Gabarito (0 = Normal, 1 = Anomalia)
* `ids_test.csv` ‚Äî Identificadores das amostras de teste

### Sa√≠da dos Modelos (`outputs/`)

* **Arquivo:** `[nome_modelo]_predictions.csv`

| Coluna          | Tipo      | Descri√ß√£o                  |
| --------------- | --------- | -------------------------- |
| `id`            | int / str | Identificador da transa√ß√£o |
| `anomaly_score` | float     | Grau de anomalia           |
| `is_anomaly`    | int       | Classifica√ß√£o bin√°ria      |

```csv
id,anomaly_score,is_anomaly
1024,0.954,1
1025,0.021,0
1026,0.110,0
```

---

## Estrutura do Reposit√≥rio

A organiza√ß√£o do reposit√≥rio separa claramente **dados**, **experimenta√ß√£o** e **c√≥digo de produ√ß√£o**, facilitando manuten√ß√£o e avalia√ß√£o.

```text
projeto-anomalia/
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ raw/                  # Dados originais imut√°veis
‚îÇ   ‚îú‚îÄ‚îÄ processed/            # Dados limpos e normalizados
‚îÇ   ‚îî‚îÄ‚îÄ mocks/                # Dados sint√©ticos para testes
‚îú‚îÄ‚îÄ notebooks/                # Explora√ß√£o e prototipagem
‚îÇ   ‚îú‚îÄ‚îÄ _eda_exploratory_data_analysis.ipynb
‚îÇ   ‚îú‚îÄ‚îÄ model_autoencoder.ipynb
‚îÇ   ‚îú‚îÄ‚îÄ model_dbscan.ipynb
‚îÇ   ‚îú‚îÄ‚îÄ model_gmm.ipynb
‚îÇ   ‚îî‚îÄ‚îÄ models_evaluation.ipynb
‚îú‚îÄ‚îÄ src/                      # C√≥digo final
‚îÇ   ‚îú‚îÄ‚îÄ preprocessing.py
‚îÇ   ‚îú‚îÄ‚îÄ evaluation.py
‚îÇ   ‚îî‚îÄ‚îÄ models/
‚îÇ       ‚îú‚îÄ‚îÄ autoencoder.py
‚îÇ       ‚îú‚îÄ‚îÄ dbscan.py
‚îÇ       ‚îî‚îÄ‚îÄ gmm.py
‚îú‚îÄ‚îÄ outputs/                  # Predi√ß√µes dos modelos
‚îú‚îÄ‚îÄ requirements.txt
‚îî‚îÄ‚îÄ README.md
```

---

## Branches e Fluxo de Trabalho

### Branches

* **main**: Produ√ß√£o (atualiza√ß√µes apenas via Pull Request)
* **feature/preprocessing**: Limpeza, EDA e split
* **feature/model-autoencoder**: Desenvolvimento do Autoencoder
* **feature/model-dbscan**: Desenvolvimento do DBSCAN
* **feature/model-gmm**: Desenvolvimento do GMM

### Fluxo de Trabalho

1. Criar branch a partir da `main`.
2. Desenvolver e testar no notebook.
3. Exportar o c√≥digo final para `src/`.
4. Abrir Pull Request para a `main`.

---

## Prepara√ß√£o do Ambiente

Para garantir compatibilidade, todos devem usar as mesmas vers√µes das bibliotecas.

### Clone o reposit√≥rio

```bash
git clone https://github.com/maqvn/Deteccao-de-Anomalias.git
```

### Crie um ambiente virtual (opcional, mas recomendado)

```bash
python -m venv venv
source venv/bin/activate  # Linux / Mac
venv\Scripts\activate     # Windows
```

### Instale as depend√™ncias

```bash
pip install -r requirements.txt
```

---

## üöÄ Guia de Execu√ß√£o (Pipeline)

Para reproduzir os resultados do projeto, siga a ordem de execu√ß√£o abaixo. O pipeline foi desenhado para que a sa√≠da de uma etapa sirva de entrada para a pr√≥xima.

### 1. Prepara√ß√£o dos Dados (Preprocessing)

Esta etapa carrega o dataset bruto, realiza a limpeza, normaliza√ß√£o e a separa√ß√£o em treino/teste. Os arquivos processados ser√£o salvos em `data/processed/`.

```bash
# Certifique-se de que o dataset (creditcard.csv) estejam em data/raw/
python src/preprocessing.py
```

### 2. Treinamento e Infer√™ncia dos Modelos

Ap√≥s o pr√©-processamento, execute os scripts dos modelos. Cada script treina o modelo, gera as predi√ß√µes no conjunto de teste e salva os resultados (CSVs e gr√°ficos) na pasta `outputs/.`

**Autoencoder (Reconstru√ß√£o):**

```bash
python src/models/autoencoder.py
```

**Gaussian Mixture Models (Probabil√≠stico):**

```Bash
python src/models/gmm.py
```

**DBSCAN (Densidade):**

```Bash
python src/models/dbscan.py
```

>    Nota: √â poss√≠vel configurar dentro de cada arquivo (vari√°vel RUN_TUNING) se deseja rodar a busca de hiperpar√¢metros (Grid Search) ou a execu√ß√£o r√°pida com os melhores par√¢metros j√° fixados.

### 3. Avalia√ß√£o Comparativa

Ap√≥s gerar as predi√ß√µes de todos os modelos, execute o script de avalia√ß√£o para gerar as m√©tricas finais e compara√ß√µes.
Bash

`python src/evaluation.py`

### 4. An√°lise Explorat√≥ria (Opcional)

Os notebooks presentes na pasta notebooks/ (como o EDA) servem para an√°lise visual e estudos preliminares. Eles n√£o s√£o estritamente necess√°rios para rodar o pipeline de produ√ß√£o, mas s√£o recomendados para o entendimento dos dados.
Bash

`jupyter notebook notebooks/`

---

## Desenvolvimento com Mocks

Enquanto os dados reais n√£o estiverem prontos:
* Rode o arquivo **src/generate_mocks.py**
* Utilize o conjunto de dados resultante em `data/mocks/`.
* Os arquivos possuem **mesma estrutura e tipos** dos dados reais.
* O c√≥digo deve funcionar alterando apenas o caminho de leitura.
