# DetecÃ§Ã£o de Anomalias (Projeto AMCD)

Projeto desenvolvido para a disciplina de **Aprendizado de MÃ¡quina e CiÃªncia de Dados (AMCD)**, com foco na comparaÃ§Ã£o sistemÃ¡tica de diferentes abordagens para **detecÃ§Ã£o de anomalias/fraudes** em dados altamente desbalanceados.

---

## Objetivo do Projeto

Implementar, avaliar e comparar trÃªs paradigmas distintos de detecÃ§Ã£o de anomalias:

* **Deep Learning** (ReconstruÃ§Ã£o)
* **Modelos Baseados em Densidade**
* **Modelos ProbabilÃ­sticos**

A comparaÃ§Ã£o Ã© realizada sob um mesmo conjunto de dados, protocolo experimental e mÃ©tricas, garantindo uma anÃ¡lise justa e reprodutÃ­vel.

---

## Modelos Implementados

1. **Autoencoder** â€” Abordagem de ReconstruÃ§Ã£o
2. **DBSCAN** â€” Abordagem de Densidade
3. **Gaussian Mixture Models (GMM)** â€” Abordagem ProbabilÃ­stica

---

## Dataset Utilizado

SerÃ¡ utilizado o dataset **Credit Card Fraud Detection**, disponibilizado publicamente no Kaggle.

### CaracterÃ­sticas Principais

* **ConteÃºdo:** TransaÃ§Ãµes de cartÃµes de crÃ©dito de clientes europeus (setembro de 2013).
* **Volume:** 284.807 transaÃ§Ãµes.
* **Desbalanceamento:** Apenas 492 fraudes (0,172%), caracterizando um cenÃ¡rio altamente desbalanceado.
* **Privacidade:** As features `V1`, `V2`, ..., `V28` resultam de uma transformaÃ§Ã£o por **PCA (Principal Component Analysis)**, aplicada para anonimizaÃ§Ã£o.
* **Features NÃ£o Transformadas:**

  * `Time`: segundos desde a primeira transaÃ§Ã£o
  * `Amount`: valor da transaÃ§Ã£o

### Justificativa da Escolha

A escolha deste dataset permite concentrar o esforÃ§o do projeto na **anÃ¡lise algorÃ­tmica** e na **sensibilidade dos modelos**, minimizando problemas oriundos de dados brutos nÃ£o estruturados.

Como as principais features jÃ¡ passaram por PCA, elas apresentam propriedades estatÃ­sticas desejÃ¡veis â€” como descorrelaÃ§Ã£o â€” que favorecem a convergÃªncia e estabilidade de modelos como **GMM** e **Autoencoders**, possibilitando uma comparaÃ§Ã£o mais precisa entre abordagens.

---

## OrganizaÃ§Ã£o do Trabalho

O projeto adota uma estrutura **modular e paralela**, permitindo que diferentes frentes avancem simultaneamente com **baixo acoplamento**. Um contrato claro de dados e responsabilidades reduz conflitos de integraÃ§Ã£o.

### DivisÃ£o de PapÃ©is e Responsabilidades

| Papel                         | Integrante     | Foco                      | Responsabilidades                                                                                                                                                                                                  |
| ----------------------------- | -------------- | ------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |
| **Eng. de Dados & AvaliaÃ§Ã£o** | *Integrante 1* | Infraestrutura e MÃ©tricas | â€¢ Limpeza, normalizaÃ§Ã£o e split dos dados<br>â€¢ GeraÃ§Ã£o de arquivos em `data/processed/`<br>â€¢ ImplementaÃ§Ã£o do `evaluation.py`<br>â€¢ CÃ¡lculo de mÃ©tricas (AUC-ROC, F1, Recall)<br>â€¢ GeraÃ§Ã£o de grÃ¡ficos comparativos |
| **Esp. em Deep Learning**     | *Integrante 2* | Autoencoder               | â€¢ ImplementaÃ§Ã£o do `autoencoder.py` (Keras/PyTorch)<br>â€¢ Ajuste do gargalo (*bottleneck*) e *learning rate*<br>â€¢ GeraÃ§Ã£o do `anomaly_score` via erro de reconstruÃ§Ã£o                                               |
| **Esp. em Densidade**         | *Integrante 3* | DBSCAN                    | â€¢ AplicaÃ§Ã£o de PCA para otimizaÃ§Ã£o<br>â€¢ ImplementaÃ§Ã£o do `dbscan.py`<br>â€¢ Ajuste de `epsilon` e `min_samples`<br>â€¢ Uso da classe `-1` como anomalia                                                                |
| **Esp. ProbabilÃ­stico**       | *Integrante 4* | GMM                       | â€¢ ImplementaÃ§Ã£o do `gmm.py`<br>â€¢ Ajuste do nÃºmero de componentes e covariÃ¢ncia<br>â€¢ CÃ¡lculo do `anomaly_score` via probabilidade invertida (1 âˆ’ P(x))                                                              |

---

## ðŸ”Œ Contrato de Interface de Dados

### Entrada dos Modelos (`data/processed/`)

* `X_train_processed.csv` â€” Features normalizadas (sem target e sem ID)
* `X_test_processed.csv` â€” Mesmo formato do treino
* `y_test.csv` â€” Gabarito (0 = Normal, 1 = Anomalia)
* `ids_test.csv` â€” Identificadores das amostras de teste

### SaÃ­da dos Modelos (`outputs/`)

* **Arquivo:** `[nome_modelo]_predictions.csv`

| Coluna          | Tipo      | DescriÃ§Ã£o                  |
| --------------- | --------- | -------------------------- |
| `id`            | int / str | Identificador da transaÃ§Ã£o |
| `anomaly_score` | float     | Grau de anomalia           |
| `is_anomaly`    | int       | ClassificaÃ§Ã£o binÃ¡ria      |

```csv
id,anomaly_score,is_anomaly
1024,0.954,1
1025,0.021,0
1026,0.110,0
```

---

## Estrutura do RepositÃ³rio

A organizaÃ§Ã£o do repositÃ³rio separa claramente **dados**, **experimentaÃ§Ã£o** e **cÃ³digo de produÃ§Ã£o**, facilitando manutenÃ§Ã£o e avaliaÃ§Ã£o.

```text
projeto-anomalia/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                  # Dados originais imutÃ¡veis (NÃƒO commitar arquivos grandes)
â”‚   â”œâ”€â”€ processed/            # Dados limpos e normalizados
â”‚   â””â”€â”€ mocks/                # Dados sintÃ©ticos para testes
â”œâ”€â”€ notebooks/                # ExploraÃ§Ã£o e prototipagem
â”‚   â”œâ”€â”€ 01_eda_analise.ipynb
â”‚   â”œâ”€â”€ 02_proto_autoencoder.ipynb
â”‚   â”œâ”€â”€ 02_proto_dbscan.ipynb
â”‚   â””â”€â”€ 02_proto_gmm.ipynb
â”œâ”€â”€ src/                      # CÃ³digo final
â”‚   â”œâ”€â”€ preprocessing.py
â”‚   â”œâ”€â”€ evaluation.py
â”‚   â””â”€â”€ models/
â”‚       â”œâ”€â”€ autoencoder.py
â”‚       â”œâ”€â”€ dbscan.py
â”‚       â””â”€â”€ gmm.py
â”œâ”€â”€ outputs/                  # PrediÃ§Ãµes dos modelos
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## Branches e Fluxo de Trabalho

### Branches

* **main**: ProduÃ§Ã£o (atualizaÃ§Ãµes apenas via Pull Request)
* **preprocessing**: Limpeza, EDA e split
* **model-autoencoder**: Desenvolvimento do Autoencoder
* **model-dbscan**: Desenvolvimento do DBSCAN
* **model-gmm**: Desenvolvimento do GMM

### Fluxo de Trabalho

1. Criar branch a partir da `main`.
2. Desenvolver e testar no notebook.
3. Exportar o cÃ³digo final para `src/`.
4. Abrir Pull Request para a `main`.

---

## ExecuÃ§Ã£o do Projeto

```bash
git clone https://github.com/maqvn/Deteccao-de-Anomalias.git
python -m venv venv
source venv/bin/activate  # Linux / Mac
venv\Scripts\activate     # Windows
pip install -r requirements.txt
```

---

## Desenvolvimento com Mocks

Enquanto os dados reais nÃ£o estiverem prontos:

* Utilize `data/mocks/`.
* Os arquivos possuem **mesma estrutura e tipos** dos dados reais.
* O cÃ³digo deve funcionar alterando apenas o caminho de leitura.
