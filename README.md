# DetecÃ§Ã£o de Anomalias (Projeto AMCD)

Projeto da disciplina de **Aprendizado de MÃ¡quina e CiÃªncia de Dados (AMCD)**.

**Objetivo:** Implementar e comparar trÃªs abordagens distintas (**Deep Learning**, **Densidade** e **ProbabilÃ­stica**) para a detecÃ§Ã£o de anomalias/fraudes em um conjunto de dados desbalanceado.

## Modelos Implementados

1. **Autoencoder** â€” Abordagem de ReconstruÃ§Ã£o
2. **DBSCAN** â€” Abordagem de Densidade
3. **Gaussian Mixture Models (GMM)** â€” Abordagem ProbabilÃ­stica

---

## Sobre o Dataset

Utilizaremos o dataset **Credit Card Fraud Detection**, disponÃ­vel no Kaggle.

### CaracterÃ­sticas

- **ConteÃºdo:** TransaÃ§Ãµes de cartÃµes de crÃ©dito de clientes europeus em setembro de 2013.
- **Volume:** 284.807 transaÃ§Ãµes.
- **Desbalanceamento:** Apenas 492 fraudes (0,172%). Dataset altamente desbalanceado, com classe positiva rara.
- **Privacidade:** As features `V1`, `V2`, ..., `V28` sÃ£o o resultado de uma transformaÃ§Ã£o **PCA (Principal Component Analysis)**, aplicada para proteger a identidade dos usuÃ¡rios.
- **Features Originais:** Apenas `Time` (segundos desde a primeira transaÃ§Ã£o) e `Amount` (valor da transaÃ§Ã£o) nÃ£o foram transformadas.

### Justificativa da Escolha

Optamos por este dataset para concentrar o esforÃ§o do projeto na **comparaÃ§Ã£o algorÃ­tmica** e na **anÃ¡lise de sensibilidade dos modelos**. Como as principais features jÃ¡ passaram por PCA, elas apresentam propriedades estatÃ­sticas relevantes â€” como descorrelaÃ§Ã£o â€” que favorecem a convergÃªncia de modelos como **GMM** e **Autoencoders**. Isso permite uma anÃ¡lise mais profunda das nuances de cada abordagem, reduzindo o impacto de ruÃ­dos tÃ­picos de dados brutos nÃ£o estruturados.

---

## Estrutura do RepositÃ³rio

O mÃ©todo de organizaÃ§Ã£o visa separar dados brutos, cÃ³digo de exploraÃ§Ã£o (notebooks) e cÃ³digo de produÃ§Ã£o (`src`).

```text
projeto-anomalia/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                  # Dados originais imutÃ¡veis (NÃƒO commitar arquivos grandes)
â”‚   â”œâ”€â”€ processed/            # Dados limpos e normalizados (gerados pelo script de limpeza)
â”‚   â””â”€â”€ mocks/                # Dados falsos para testes de integraÃ§Ã£o
â”œâ”€â”€ notebooks/                # Ãrea de experimentaÃ§Ã£o e rascunho
â”‚   â”œâ”€â”€ 01_eda_analise.ipynb
â”‚   â”œâ”€â”€ 02_proto_autoencoder.ipynb
â”‚   â”œâ”€â”€ 02_proto_dbscan.ipynb
â”‚   â””â”€â”€ 02_proto_gmm.ipynb
â”œâ”€â”€ src/                      # CÃ³digo final modularizado
â”‚   â”œâ”€â”€ preprocessing.py      # FunÃ§Ãµes de limpeza e split
â”‚   â”œâ”€â”€ evaluation.py         # FunÃ§Ãµes para curvas ROC e mÃ©tricas
â”‚   â””â”€â”€ models/               # Scripts finais dos modelos
â”‚       â”œâ”€â”€ autoencoder.py
â”‚       â”œâ”€â”€ dbscan.py
â”‚       â””â”€â”€ gmm.py
â”œâ”€â”€ outputs/                  # PrediÃ§Ãµes salvas pelos modelos (CSV)
â”œâ”€â”€ requirements.txt          # DependÃªncias do projeto
â””â”€â”€ README.md                 # Este arquivo
```

---

## Branches

* **main**: ProduÃ§Ã£o. atualizaÃ§Ã£o exclusivamente via *Pull Request* (PR).
* **preprocessing**: Limpeza, EDA e split dos dados.
* **model-autoencoder**: Desenvolvimento da Rede Neural.
* **model-dbscan**: Desenvolvimento do DBSCAN e PCA.
* **model-gmm**: Desenvolvimento do GMM e anÃ¡lise de distribuiÃ§Ã£o.

### Fluxo de Trabalho

1. Crie sua branch a partir da `main`.
2. Desenvolva e teste no seu notebook.
3. Exporte o cÃ³digo limpo para a pasta `src/`.
4. Abra um *Pull Request* para a `main` ao finalizar.

---

## Contrato de Interface de Dados

Para garantir a paralelizaÃ§Ã£o do trabalho, os formatos de entrada e saÃ­da sÃ£o prÃ©-definidos.

### Entrada dos modelos

Todos os modelos devem ler os dados da pasta `data/processed/`:

* **X_train_processed.csv**
  Features numÃ©ricas normalizadas, sem coluna alvo (`target`) e sem ID.

* **X_test_processed.csv**
  Mesmo formato do conjunto de treino.

* **y_test.csv**
  Gabarito oficial para validaÃ§Ã£o (coluna Ãºnica binÃ¡ria: `0 = Normal`, `1 = Anomalia`).

* **ids_test.csv**
  IDs correspondentes Ã s linhas de teste (para cruzamento de resultados).

### SaÃ­da dos modelos

Todo modelo deve salvar suas prediÃ§Ãµes na pasta `outputs/`, seguindo **exatamente** este formato:

* **Nome do arquivo:** `[nome_modelo]_predictions.csv`
  Exemplo: `autoencoder_predictions.csv`

#### Estrutura do CSV

| Coluna          | Tipo      | DescriÃ§Ã£o                                               |
| --------------- | --------- | ------------------------------------------------------- |
| `id`            | int / str | Identificador da transaÃ§Ã£o (deve coincidir com o input) |
| `anomaly_score` | float     | Grau de anomalia (quanto maior, mais anÃ´malo)           |
| `is_anomaly`    | int       | ClassificaÃ§Ã£o binÃ¡ria baseada no *threshold* (0 ou 1)   |

#### ğŸ“Œ Exemplo de CSV de SaÃ­da

```csv
id,anomaly_score,is_anomaly
1024,0.954,1
1025,0.021,0
1026,0.110,0
```

---

## Como Executar (Ambiente)

Para garantir compatibilidade, todos devem usar as mesmas versÃµes das bibliotecas.

### Clone o repositÃ³rio

```bash
git clone https://github.com/maqvn/Deteccao-de-Anomalias.git
```

### Crie um ambiente virtual (opcional, mas recomendado)

```bash
python -m venv venv
source venv/bin/activate  # Linux / Mac
venv\Scripts\activate     # Windows
```

### Instale as dependÃªncias

```bash
pip install -r requirements.txt
```

---

## Desenvolvimento com Mocks

Enquanto os dados reais nÃ£o estiverem prontos (limpeza em andamento), utilize os arquivos da pasta `data/mocks/`.

* Possuem a **mesma estrutura de colunas e tipos de dados** dos arquivos reais.
* Seu cÃ³digo deve funcionar alterando apenas o caminho de leitura de `data/processed/` para `data/mocks/`.
